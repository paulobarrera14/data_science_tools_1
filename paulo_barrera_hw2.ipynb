{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2 total points 5\n",
    "# Solve following problems. Each problem is worth 1 point. Your answers should be written in one line. Total points 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1(1 point) Remove the blank lines from the customer_record.csv using grep command and regular expression. You may have to read grep documentation to look for more otpions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\" color=\"red\"> Run following cell to create customer_record.csv </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-09-20T19:54:59.874387Z",
     "start_time": "2023-09-20T19:54:59.749945500Z"
    }
   },
   "outputs": [],
   "source": [
    "!echo \"customer,items, type, quantity\" > customer_history.csv; echo \"Allen, Statistical analysis, book, 2\" >> customer_history.csv;echo \"\">> customer_history.csv; echo \"Jhon, Kasa Smart Wi-Fi Plug, electronics, 3\" >>customer_history.csv; echo \"Tim,Unix Shell Programming, Book, 3\" >> customer_history.csv; echo \"\">> customer_history.csv; echo \"Allen,Python for Data Analysis, Book, 1\">> customer_history.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-09-20T19:55:04.823311800Z",
     "start_time": "2023-09-20T19:55:04.720413500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer,items, type, quantity\r\n",
      "Allen, Statistical analysis, book, 2\r\n",
      "\r\n",
      "Jhon, Kasa Smart Wi-Fi Plug, electronics, 3\r\n",
      "Tim,Unix Shell Programming, Book, 3\r\n",
      "\r\n",
      "Allen,Python for Data Analysis, Book, 1\r\n"
     ]
    }
   ],
   "source": [
    "! cat customer_history.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-09-20T20:03:37.415160700Z",
     "start_time": "2023-09-20T20:03:37.149960500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer,items, type, quantity\r\n",
      "Allen, Statistical analysis, book, 2\r\n",
      "Jhon, Kasa Smart Wi-Fi Plug, electronics, 3\r\n",
      "Tim,Unix Shell Programming, Book, 3\r\n",
      "Allen,Python for Data Analysis, Book, 1\r\n"
     ]
    }
   ],
   "source": [
    "# ^[ \\t]*$ says ^ anchor here, [ \\t]* match to any whitespace then match to zero or more of the preceding element, $ end\n",
    "! grep -v '^[ \\t]*$' customer_history.csv > new_file.csv\n",
    "! cat new_file.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2(1 point)  Use the previous grep command and a combination of commands using pipe(|) to print uniq customer names in capital letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-09-20T20:08:37.362926200Z",
     "start_time": "2023-09-20T20:08:37.253780400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLEN\r\n",
      "JHON\r\n",
      "TIM\r\n"
     ]
    }
   ],
   "source": [
    "# do the same grep command then we cut the first column of the file, then use tr to translate all names to capital letters, we pipe sort then pipe uniq to output the unique customer names in caps. Addition of tail was added so that we could skil the first line of input being that it is the column name.\n",
    "! grep -v '^[ \\t]*$' customer_history.csv | tail -n +2 | cut -d',' -f1 | tr 'a-z' 'A-Z' | sort | uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some other  useful commands we didn't cover in the class are *mkdir, find* and *wc*.\n",
    "# Look for their documentation. Sometime we forget where the files are in the filesystem. The *find* command is really useful for searching files in filesystem. To learn these commands we wil use them in following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make  dataset_zyx_dec_2050/train and dataset_zyx_dec_2050/validation directory and add some files in them. \n",
    "\n",
    "<font color='red' size= 4 >Run the following commands to make  directories and files. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-09-20T20:17:25.824130100Z",
     "start_time": "2023-09-20T20:17:25.608829700Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p dataset_zyx_dec_2050/train\n",
    "!mkdir -p dataset_zyx_dec_2050/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T20:17:34.343515600Z",
     "start_time": "2023-09-20T20:17:33.843880800Z"
    }
   },
   "outputs": [],
   "source": [
    "!for i in $(seq   5); do touch dataset_zyx_dec_2050/validation/cat$i.jpg ;done\n",
    "!for i in $(seq   5); do touch dataset_zyx_dec_2050/validation/cat$i.tfrecord ;done\n",
    "!for i in $(seq   5); do touch dataset_zyx_dec_2050/train/cat$i.jpg ;done\n",
    "!for i in $(seq   5); do touch dataset_zyx_dec_2050/train/dog$i.jpg ;done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command displays the contents of dataset_zyx_dec_2050/validation and dataset_zyx_dec_2050/train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T20:17:46.426411600Z",
     "start_time": "2023-09-20T20:17:46.314534100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat1.jpg  cat3.jpg  cat5.jpg  dog2.jpg\tdog4.jpg\r\n",
      "cat2.jpg  cat4.jpg  dog1.jpg  dog3.jpg\tdog5.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls dataset_zyx_dec_2050/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T20:18:02.942564Z",
     "start_time": "2023-09-20T20:18:02.831954500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat1.jpg       cat2.jpg       cat3.jpg\t     cat4.jpg\t    cat5.jpg\r\n",
      "cat1.tfrecord  cat2.tfrecord  cat3.tfrecord  cat4.tfrecord  cat5.tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "!ls dataset_zyx_dec_2050/validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3(1 point) Print all the files starting with the name *cat* in the subfolders of dataset_zyx_dec_2050  using find command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T20:19:52.865715300Z",
     "start_time": "2023-09-20T20:19:52.696516300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset_zyx_dec_2050/train/cat1.jpg\r\n",
      "./dataset_zyx_dec_2050/train/cat2.jpg\r\n",
      "./dataset_zyx_dec_2050/train/cat3.jpg\r\n",
      "./dataset_zyx_dec_2050/train/cat4.jpg\r\n",
      "./dataset_zyx_dec_2050/train/cat5.jpg\r\n",
      "./dataset_zyx_dec_2050/validation/cat1.jpg\r\n",
      "./dataset_zyx_dec_2050/validation/cat1.tfrecord\r\n",
      "./dataset_zyx_dec_2050/validation/cat2.jpg\r\n",
      "./dataset_zyx_dec_2050/validation/cat2.tfrecord\r\n",
      "./dataset_zyx_dec_2050/validation/cat3.jpg\r\n",
      "./dataset_zyx_dec_2050/validation/cat3.tfrecord\r\n",
      "./dataset_zyx_dec_2050/validation/cat4.jpg\r\n",
      "./dataset_zyx_dec_2050/validation/cat4.tfrecord\r\n",
      "./dataset_zyx_dec_2050/validation/cat5.jpg\r\n",
      "./dataset_zyx_dec_2050/validation/cat5.tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "#write your command in next line\n",
    "# Hint ./use dataset_zyx_dec_2050 and read about -name option in the find command\n",
    "# doing find . tells the computer we are looking in the current directory, so we can skip some steps, 'cat*' is telling the computer and file that is named cat with anything following it\n",
    "!find . -type f -name 'cat*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4(.5 point) Count number of cat files using pipe and *wc* command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T20:29:25.100495300Z",
     "start_time": "2023-09-20T20:29:24.973236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\r\n"
     ]
    }
   ],
   "source": [
    "#write your commands in the next line\n",
    "#addition of wc -l counts the lines outputted from the find in the current directory\n",
    "!find . -type f -name 'cat*' | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5(.5) Using answer of Q2, find the total number of unique customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T20:43:28.107119500Z",
     "start_time": "2023-09-20T20:43:27.998359600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\r\n"
     ]
    }
   ],
   "source": [
    "# write your code in the next line\n",
    "# wc -l takes the count of the answer from Q2 and just outputs the count of the uniquely sorted customers\n",
    "!grep -v '^[ \\t]*$' customer_history.csv | tail -n +2 | cut -d',' -f1 | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's say you work for an e-commerce company and you are on call. Due to some recent feature pushed to the production, a severity 1 ticket is raised. The ticket states that some to the customers are charged multiple time this month. Your task is to quickly find the affected customer and manually credit back the amount.\n",
    "\n",
    "<font size=\"4\" color = \"red\"> Run the followoing cell to generate the the  payment_gateway.logxx file </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T04:35:06.471914100Z",
     "start_time": "2023-09-22T04:35:06.451914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"customer:2150:credit_card:xxxx-xxxx-xxxx:charged:\\$50\n",
    "customer:2350:credit_card:xxxx-xxxx-xxxx:charged:\\$20\n",
    "Paymenet gateway: STATUS 200\n",
    "customer:3456 payment failed\n",
    "customer:3350:credit_card:xxxx-xxxx-xxxx:charged:\\$71\n",
    "customer:4350:credit_card:xxxx-xxxx-xxxx:charged:\\$50\n",
    "customer:2350:credit_card:xxxx-xxxx-xxxx:charged:\\$20\n",
    "ncustomer:2150:credit_card:xxxx-xxxx-xxxx:charged:\\$50\n",
    "customer:3350:credit_card:xxxx-xxxx-xxxx:charged:\\$71\n",
    "customer:2350:credit_card:xxxx-xxxx-xxxx:charged:\\$20\n",
    "customer:2350:credit_card:xxxx-xxxx-xxxx:declined charged:attempt:3\" > payment_gateway.logxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T04:35:22.898449400Z",
     "start_time": "2023-09-22T04:35:22.777698900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer:2150:credit_card:xxxx-xxxx-xxxx:charged:$50\r\n",
      "customer:2350:credit_card:xxxx-xxxx-xxxx:charged:$20\r\n",
      "Paymenet gateway: STATUS 200\r\n",
      "customer:3456 payment failed\r\n",
      "customer:3350:credit_card:xxxx-xxxx-xxxx:charged:$71\r\n",
      "customer:4350:credit_card:xxxx-xxxx-xxxx:charged:$50\r\n",
      "customer:2350:credit_card:xxxx-xxxx-xxxx:charged:$20\r\n",
      "ncustomer:2150:credit_card:xxxx-xxxx-xxxx:charged:$50\r\n",
      "customer:3350:credit_card:xxxx-xxxx-xxxx:charged:$71\r\n",
      "customer:2350:credit_card:xxxx-xxxx-xxxx:charged:$20\r\n",
      "customer:2350:credit_card:xxxx-xxxx-xxxx:declined charged:attempt:3\r\n"
     ]
    }
   ],
   "source": [
    "# Here is the file contents\n",
    "!cat payment_gateway.logxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6(1 point) Use payment_gateway.logxx file to find the number of times a customer is charged and the line corresponding to the customer  record. Only print lines for customers charged more than one time.\n",
    "\n",
    "Hint:\n",
    "for customer 2350 line output should be\n",
    "\n",
    "3 customer:2350:credit_card:xxxx-xxxx-xxxx:charged:$20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T04:37:31.788843300Z",
     "start_time": "2023-09-22T04:37:31.678767300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 2150\r\n",
      "      4 2350\r\n",
      "      2 3350\r\n"
     ]
    }
   ],
   "source": [
    "# Write you commands in the next line\n",
    "#this sorts the file then counts the amount of times a customer shows up, grep -v '^ *1' filters for a specific pattern being ^ *1, so it filters every instance from uniq -c that only shows up once (^ anchor, * matches 0 or more spaces, 1 matches to the 1 from the uniq -c)\n",
    "#attempt 1\n",
    "#!sort payment_gateway.logxx | uniq -c | grep -v '^ *1'\n",
    "#attempt 2\n",
    "#!sed 's/customer/ncustomer/' payment_gateway.logxx | uniq -c | grep -v '^ *1'\n",
    "#attempt 3: awk -F':'' '{print $2} splits each line by the delimiter : and prints the second field bring the customer number, ignoring the typo. Sort sorts the outputs then uniq -c counts the duplicates and removes any extra lines, grep -v '^ *1' filters out all the instances where there is only one customer number outputting the customer numbers that show up multiple times\n",
    "!awk -F':' '{print $2}' payment_gateway.logxx | sort | uniq -c | grep -v '^ *1'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
